{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Baby name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://images.unsplash.com/photo-1519689680058-324335c77eba?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1050&q=80)\n",
    "\n",
    "Photo by [Valeria Zoncoll](https://unsplash.com/photos/AVGc87j_vNA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this challenge, you will generate baby names using recurrent neural networks!\n",
    "\n",
    "The used dataset is in the file `names.txt`, a file encoded in `'ISO-8859-1'`, containing more than 10 000 names.\n",
    "\n",
    "First load it, and have a look at the names, and clean the dataset if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaliyah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aapeli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aapo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aarne</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name\n",
       "0  aaliyah\n",
       "1   aapeli\n",
       "2     aapo\n",
       "3    aaren\n",
       "4    aarne"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Load the dataset and explore it\n",
    "### STRIP_START ###\n",
    "import pandas as pd\n",
    "names=pd.read_csv('names.txt', encoding=\"ISO-8859-1\")\n",
    "\n",
    "names = names.drop_duplicates()\n",
    "\n",
    "names.head()\n",
    "### STRIP_END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RNN needs to understand where is the beginning and the end of a word. So we need to add a new character at the beginning of every word, for example `'\\t'` (it could be anything else as long as it can be identified easily). We can also add `'\\n'` to the end of every word as the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add '\\t' at the beginning of every word\n",
    "### STRIP_START ###\n",
    "names['name'] =names[\"name\"].apply(lambda x: '\\t'+str(x)+'\\n')\n",
    "### STRIP_END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate names, we will have to play at the character level: we will train a RNN to predict the next character, knowing the previous one. So, compute a list of all the possible characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of characters 55\n",
      "{'ö', 'à', 'ä', 'ô', 'ã', 'x', 'f', 'ø', 'm', 'ì', 'c', 'l', 'k', 'b', 'u', 'ï', 'i', 'y', 'ú', 'ò', 'ê', '\\t', 'n', 'é', 'ë', 'z', 'ñ', 'a', 'ü', 'r', 'o', 'ù', 'd', 'õ', 'h', 't', 'æ', 'w', 'á', 's', 'p', '-', 'è', 'ð', 'ç', 'ó', 'í', 'j', 'þ', 'e', 'q', 'v', 'g', 'å', '\\n'}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compute and display the list of all possible characters\n",
    "### STRIP_START ###\n",
    "# Get the vocab dict\n",
    "all_chars=set()\n",
    "for name in names.name:\n",
    "    for c in name:\n",
    "        if c not in all_chars:\n",
    "            all_chars.add(c)\n",
    "all_chars.add('\\n')\n",
    "\n",
    "print('number of characters', len(all_chars))\n",
    "print(all_chars)\n",
    "### STRIP_END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get 55 characters, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual when playing with characters (or words), we will convert them into integers. So build a dictionary `char_to_idx` that, given a character as key, returns an integer. And build the opposite dictionary `idx_to_char` that, given an integer as key, returns the corresponding character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\t': 0,\n",
       " '\\n': 1,\n",
       " '-': 2,\n",
       " 'a': 3,\n",
       " 'b': 4,\n",
       " 'c': 5,\n",
       " 'd': 6,\n",
       " 'e': 7,\n",
       " 'f': 8,\n",
       " 'g': 9,\n",
       " 'h': 10,\n",
       " 'i': 11,\n",
       " 'j': 12,\n",
       " 'k': 13,\n",
       " 'l': 14,\n",
       " 'm': 15,\n",
       " 'n': 16,\n",
       " 'o': 17,\n",
       " 'p': 18,\n",
       " 'q': 19,\n",
       " 'r': 20,\n",
       " 's': 21,\n",
       " 't': 22,\n",
       " 'u': 23,\n",
       " 'v': 24,\n",
       " 'w': 25,\n",
       " 'x': 26,\n",
       " 'y': 27,\n",
       " 'z': 28,\n",
       " 'à': 29,\n",
       " 'á': 30,\n",
       " 'ã': 31,\n",
       " 'ä': 32,\n",
       " 'å': 33,\n",
       " 'æ': 34,\n",
       " 'ç': 35,\n",
       " 'è': 36,\n",
       " 'é': 37,\n",
       " 'ê': 38,\n",
       " 'ë': 39,\n",
       " 'ì': 40,\n",
       " 'í': 41,\n",
       " 'ï': 42,\n",
       " 'ð': 43,\n",
       " 'ñ': 44,\n",
       " 'ò': 45,\n",
       " 'ó': 46,\n",
       " 'ô': 47,\n",
       " 'õ': 48,\n",
       " 'ö': 49,\n",
       " 'ø': 50,\n",
       " 'ù': 51,\n",
       " 'ú': 52,\n",
       " 'ü': 53,\n",
       " 'þ': 54}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Compute the idx_to_char and char_to_idx dict\n",
    "### STRIP_START ###\n",
    "# max length of a name is 11\n",
    "char_to_idx = { ch:i for i,ch in enumerate(sorted(all_chars)) }\n",
    "idx_to_char = { i:ch for i,ch in enumerate(sorted(all_chars)) }\n",
    "char_to_idx\n",
    "### STRIP_END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going into the neural network part, we have one more step: **create the X and y data**!\n",
    "\n",
    "So the **X** data is going to be, for every name, all but the `'\\n'` character. The **y** data will be all but the `'\\t'` character.\n",
    "\n",
    "Indeed, we will try to predict the following character knowing the previous. To the **X** does not need the final character, and the **y** does not need the first character.\n",
    "\n",
    "Create the columns X and y to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\taaliyah\\n</td>\n",
       "      <td>\\taaliyah</td>\n",
       "      <td>aaliyah\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\taapeli\\n</td>\n",
       "      <td>\\taapeli</td>\n",
       "      <td>aapeli\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\taapo\\n</td>\n",
       "      <td>\\taapo</td>\n",
       "      <td>aapo\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\taaren\\n</td>\n",
       "      <td>\\taaren</td>\n",
       "      <td>aaren\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\taarne\\n</td>\n",
       "      <td>\\taarne</td>\n",
       "      <td>aarne\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name          X          y\n",
       "0  \\taaliyah\\n  \\taaliyah  aaliyah\\n\n",
       "1   \\taapeli\\n   \\taapeli   aapeli\\n\n",
       "2     \\taapo\\n     \\taapo     aapo\\n\n",
       "3    \\taaren\\n    \\taaren    aaren\\n\n",
       "4    \\taarne\\n    \\taarne    aarne\\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Create the columns X and y\n",
    "### STRIP_START ###\n",
    "names['X'] = names[\"name\"].apply(lambda x: x[:len(x)-1])\n",
    "names['y'] = names[\"name\"].apply(lambda x: x[1:len(x)])\n",
    "names.head()\n",
    "### STRIP_END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using your `char_to_idx` dict, compute the corresponding `X` and `y` containing, for each name, a list of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the X and y variables containing integers only\n",
    "### STRIP_START ###\n",
    "X = names['X'].apply(lambda x: [char_to_idx[c] for c in x])\n",
    "y = names['y'].apply(lambda x: [char_to_idx[c] for c in x])\n",
    "### STRIP_END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was complicated, but are now in a known case, use keras and `pad_sequence()` function to get a proper `X` and `y` variables with a `maxlen=16`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11497, 16), (11497, 16))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Use pad_sequences to get only sequences of length 16 for each name\n",
    "### STRIP_START ###\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "maxlen = 16\n",
    "\n",
    "X_train = sequence.pad_sequences(X,\n",
    "                                 value=0,\n",
    "                                 padding='post',\n",
    "                                 maxlen=maxlen)\n",
    "\n",
    "y_train = sequence.pad_sequences(y,\n",
    "                                 value=0,\n",
    "                                 padding='post',\n",
    "                                 maxlen=maxlen)\n",
    "X_train.shape, y_train.shape\n",
    "### STRIP_END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, using the function `to_categorical()`, make the one-hot-encoding needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11497, 16, 55), (11497, 16, 55))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: use to_categorical to perform one hot encoding\n",
    "### STRIP_START ###\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "X_train = to_categorical(X_train)\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "X_train.shape, y_train.shape\n",
    "### STRIP_END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should finally have arrays of shape `(number of names, 16, 55)`:\n",
    "- `16` is the sequence length\n",
    "- `55` is the number of possible characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have to build a neural network. You can for example use one or two layers of GRU (or LSTM). Do not forget to set `return_sequences=True`. \n",
    "\n",
    "Then you will have to add a `TimeDistributed(Dense(55))` with a softmax activation function. This layer will handle the fact you have a dense layer at each time step with a softmax prediction of the next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build the neural network\n",
    "### STRIP_START ###\n",
    "from tensorflow.keras.layers import GRU, Dense, TimeDistributed\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GRU(32, input_shape=(maxlen, len(all_chars)), return_sequences=True))\n",
    "model.add(GRU(32, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(len(all_chars), activation='softmax')))\n",
    "### STRIP_END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, train your model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "11497/11497 [==============================] - 4s 317us/sample - loss: 2.0612\n",
      "Epoch 2/50\n",
      "11497/11497 [==============================] - 3s 225us/sample - loss: 1.3707\n",
      "Epoch 3/50\n",
      "11497/11497 [==============================] - 3s 248us/sample - loss: 1.2475\n",
      "Epoch 4/50\n",
      "11497/11497 [==============================] - 3s 254us/sample - loss: 1.1813\n",
      "Epoch 5/50\n",
      "11497/11497 [==============================] - 4s 378us/sample - loss: 1.1545\n",
      "Epoch 6/50\n",
      "11497/11497 [==============================] - 3s 297us/sample - loss: 1.1393\n",
      "Epoch 7/50\n",
      "11497/11497 [==============================] - 3s 287us/sample - loss: 1.1278\n",
      "Epoch 8/50\n",
      "11497/11497 [==============================] - 4s 335us/sample - loss: 1.1178\n",
      "Epoch 9/50\n",
      "11497/11497 [==============================] - 4s 326us/sample - loss: 1.1082\n",
      "Epoch 10/50\n",
      "11497/11497 [==============================] - 4s 318us/sample - loss: 1.1009\n",
      "Epoch 11/50\n",
      "11497/11497 [==============================] - 4s 335us/sample - loss: 1.0949\n",
      "Epoch 12/50\n",
      "11497/11497 [==============================] - 4s 316us/sample - loss: 1.0897\n",
      "Epoch 13/50\n",
      "11497/11497 [==============================] - 4s 310us/sample - loss: 1.0851\n",
      "Epoch 14/50\n",
      "11497/11497 [==============================] - 4s 314us/sample - loss: 1.0807\n",
      "Epoch 15/50\n",
      "11497/11497 [==============================] - 4s 309us/sample - loss: 1.0771\n",
      "Epoch 16/50\n",
      "11497/11497 [==============================] - 4s 316us/sample - loss: 1.0733\n",
      "Epoch 17/50\n",
      "11497/11497 [==============================] - 4s 322us/sample - loss: 1.0702\n",
      "Epoch 18/50\n",
      "11497/11497 [==============================] - 4s 319us/sample - loss: 1.0668\n",
      "Epoch 19/50\n",
      "11497/11497 [==============================] - 4s 327us/sample - loss: 1.0633\n",
      "Epoch 20/50\n",
      "11497/11497 [==============================] - 4s 318us/sample - loss: 1.0611\n",
      "Epoch 21/50\n",
      "11497/11497 [==============================] - 4s 317us/sample - loss: 1.0582\n",
      "Epoch 22/50\n",
      "11497/11497 [==============================] - 3s 300us/sample - loss: 1.0555\n",
      "Epoch 23/50\n",
      "11497/11497 [==============================] - 4s 353us/sample - loss: 1.0532\n",
      "Epoch 24/50\n",
      "11497/11497 [==============================] - 4s 305us/sample - loss: 1.0510\n",
      "Epoch 25/50\n",
      "11497/11497 [==============================] - 4s 357us/sample - loss: 1.0484\n",
      "Epoch 26/50\n",
      "11497/11497 [==============================] - 4s 332us/sample - loss: 1.0460\n",
      "Epoch 27/50\n",
      "11497/11497 [==============================] - 4s 325us/sample - loss: 1.0439\n",
      "Epoch 28/50\n",
      "11497/11497 [==============================] - 4s 317us/sample - loss: 1.0419\n",
      "Epoch 29/50\n",
      "11497/11497 [==============================] - 4s 327us/sample - loss: 1.0405\n",
      "Epoch 30/50\n",
      "11497/11497 [==============================] - 4s 322us/sample - loss: 1.0381\n",
      "Epoch 31/50\n",
      "11497/11497 [==============================] - 4s 308us/sample - loss: 1.0362\n",
      "Epoch 32/50\n",
      "11497/11497 [==============================] - 3s 304us/sample - loss: 1.0346\n",
      "Epoch 33/50\n",
      "11497/11497 [==============================] - 4s 315us/sample - loss: 1.0325\n",
      "Epoch 34/50\n",
      "11497/11497 [==============================] - 4s 332us/sample - loss: 1.0308\n",
      "Epoch 35/50\n",
      "11497/11497 [==============================] - 4s 311us/sample - loss: 1.0294\n",
      "Epoch 36/50\n",
      "11497/11497 [==============================] - 4s 323us/sample - loss: 1.0279\n",
      "Epoch 37/50\n",
      "11497/11497 [==============================] - 4s 322us/sample - loss: 1.0258\n",
      "Epoch 38/50\n",
      "11497/11497 [==============================] - 4s 307us/sample - loss: 1.0247\n",
      "Epoch 39/50\n",
      "11497/11497 [==============================] - 4s 333us/sample - loss: 1.0228\n",
      "Epoch 40/50\n",
      "11497/11497 [==============================] - 3s 301us/sample - loss: 1.0214\n",
      "Epoch 41/50\n",
      "11497/11497 [==============================] - 4s 320us/sample - loss: 1.0200\n",
      "Epoch 42/50\n",
      "11497/11497 [==============================] - 4s 308us/sample - loss: 1.0182\n",
      "Epoch 43/50\n",
      "11497/11497 [==============================] - 4s 315us/sample - loss: 1.0170\n",
      "Epoch 44/50\n",
      "11497/11497 [==============================] - 4s 314us/sample - loss: 1.0153\n",
      "Epoch 45/50\n",
      "11497/11497 [==============================] - 4s 316us/sample - loss: 1.0139\n",
      "Epoch 46/50\n",
      "11497/11497 [==============================] - 4s 310us/sample - loss: 1.0127\n",
      "Epoch 47/50\n",
      "11497/11497 [==============================] - 4s 321us/sample - loss: 1.0114\n",
      "Epoch 48/50\n",
      "11497/11497 [==============================] - 4s 330us/sample - loss: 1.0099\n",
      "Epoch 49/50\n",
      "11497/11497 [==============================] - 4s 328us/sample - loss: 1.0091\n",
      "Epoch 50/50\n",
      "11497/11497 [==============================] - 4s 341us/sample - loss: 1.0075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7feafd7b9e10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: fit the model\n",
    "### STRIP_START ###\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=50)\n",
    "### STRIP_END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step will be to generate names, through a function `generate_names()`. \n",
    "\n",
    "To do so, you will have to give the output of the previous time step prediction as input to the next time step.\n",
    "\n",
    "You will have to use the method `predict_proba` of your model, as will as the method `numpy.random.choice`.\n",
    "\n",
    "Finally, use your function to generate some names!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tlida\n",
      "\tivaert\n",
      "\tgerdadd\n",
      "\tgrand\n",
      "\thada\n",
      "\tpekra\n",
      "\tmarim\n",
      "\tsim\n",
      "\tvede\n",
      "\tinceline\n",
      "\tdedwa\n",
      "\tcenka\n",
      "\tgroxen\n",
      "\tagn\n",
      "\tluken\n",
      "\tperzs\n",
      "\tklildit\n",
      "\tavsgeron\n",
      "\tozima\n",
      "\tahdel\n"
     ]
    }
   ],
   "source": [
    "# TODO: implement the function generate_names\n",
    "### STRIP_START ###\n",
    "from generate import generate_n_names\n",
    "\n",
    "generate_n_names(20, maxlen, char_to_idx, model)\n",
    "### STRIP_END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case this looks too complicated (indeed it is far from being simple), you can use the function `generate_n_names()` in the file `generate.py`. But first have a look at it and try to understand what it does!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have more time, you can try to improve the results by tuning your neural network hyperparameters.\n",
    "\n",
    "You can also use the original file, `Prenoms.csv`, and use only names from a given origin, to build a model more specific for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: This method can be applied to almost anything: you can generate music, shakespeare, lyrics... using this method. All it takes is to change the data preprocessing and adapt the dimensions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
