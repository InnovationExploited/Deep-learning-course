{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Boxes Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://images.unsplash.com/photo-1512418490979-92798cec1380?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1050&q=80)\n",
    "\n",
    "Photo by [Leone Venter](https://unsplash.com/photos/mTkXSSScrzw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will use the TensorFlow object detection API to get bounding boxes and classes on images.\n",
    "\n",
    "But first, we need some installation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will here follow the installation guide of the API, that can be found [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.1. Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do is to install all needed dependencies (if not installed yet):\n",
    "- pip install --user Cython\n",
    "- pip install --user contextlib2\n",
    "- pip install --user pillow\n",
    "- pip install --user lxml\n",
    "- pip install --user jupyter\n",
    "- pip install --user matplotlib\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.2. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will download the models (i.e. the architecture and trained weights of neural networks). They are available in the so called [detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md).\n",
    "\n",
    "For this exercise, we will use first the **faster_rcnn_inception_v2_coco** model: download it.\n",
    "\n",
    "You should get a .tar.gz file, containing (among other files) `frozen-inference-graph.pb`: this is what we will use to perform object detection.\n",
    "\n",
    "So extract it in the `data/models` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to clone the `models` part of the TensorFlow Object Detection API. To do so, open your terminal, and in the **root of the vivadata folder**, clone the repo with the following command:\n",
    "\n",
    "```\n",
    "git clone https://github.com/tensorflow/models.git\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, **do not commit those files**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.3. Protobuf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Protobuf (for protocol buffer) is a Google system, that will be used for configuration.\n",
    "\n",
    "Go now in the newly cloned repo at the root of the vivadata folder `models/research`, and launch the configuration using protobuf:\n",
    "```\n",
    "protoc object_detection/protos/*.proto --python_out=.\n",
    "```\n",
    "\n",
    "You may need to install the protobuf compiler using the following command on Ubuntu: `sudo apt-get install protobuf-compiler`\n",
    "\n",
    "For MacOS use `brew install protobuf`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.1. Setting the paths to the trained graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we set the paths of the model we will use in a variable called `PATH_TO_CKPT`: this is the path to the `frozen_inference_graph.pb` that you downloaded in I.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: define the variable PATH_TO_CKPT\n",
    "### STRIP_START ###\n",
    "PATH_TO_CKPT = '../../../../../../data/models/frozen_inference_graph.pb'\n",
    "### STRIP_END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you have to set the paths to the labels: indeed labels are just numbers, but we want them to be strings so that we can understand! The table to do so is in the folder you cloned: `models/research/object_detection/data/mscoco_label_map.pbtxt`.\n",
    "\n",
    "Put that path into the variable `PATH_TO_LABELS`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: define the variable PATH_TO_LABELS\n",
    "### STRIP_START ###\n",
    "PATH_TO_LABELS = '../../../../../../models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
    "### STRIP_END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at this file. How many classes are there? Put that value into a variable called `NUM_CLASSES`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: define the variable NUM_CLASSES\n",
    "### STRIP_START ###\n",
    "NUM_CLASSES = 90\n",
    "### STRIP_END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2. Playing with labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the module within the object detection API called `label_map_util`. To import it, you may need to add the path of this library to the current path, to do so, use `sys.path.append(path)` of the `sys` python module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: import label_map_util\n",
    "### STRIP_START ###\n",
    "import sys\n",
    "sys.path.append('../../../../../../models/research')\n",
    "from object_detection.utils import label_map_util\n",
    "### STRIP_END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.3. Testing object detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We made some utils functions for you, so that you will just have to put them together to do the object detection.\n",
    "\n",
    "First, with the following code, you will compute the graph with the trained weights you downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Compute the graph\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you will have to use the functions `run_inference_for_single_image` provided in the `utils.py` file. This function is easy to find on the TensorFlow Object Detection API. Have a look at it and try to understand the big picture.\n",
    "\n",
    "Then use it on the provided test images: `image1.jpg`, `image2` and `image3.jpg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Use run_inference_for_single_image to compute the object detection\n",
    "### STRIP_START ###\n",
    "from utils import run_inference_for_single_image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "im1 = plt.imread('image1.jpg')\n",
    "im2 = plt.imread('image2.jpg')\n",
    "im3 = plt.imread('image3.jpg')\n",
    "\n",
    "output_dict1 = run_inference_for_single_image(im1, detection_graph)\n",
    "output_dict2 = run_inference_for_single_image(im2, detection_graph)\n",
    "output_dict3 = run_inference_for_single_image(im3, detection_graph)\n",
    "\n",
    "### STRIP_END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now have a look at the output dictionary, can you understand its content? Save them in pickle format, in the next part of the challenge we will display and post process them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Save the output dicts in pickle\n",
    "### STRIP_START ###\n",
    "import pickle\n",
    "\n",
    "pickle.dump(output_dict1, open(\"output_im1.p\", \"wb\"))\n",
    "pickle.dump(output_dict2, open(\"output_im2.p\", \"wb\"))\n",
    "pickle.dump(output_dict3, open(\"output_im3.p\", \"wb\"))\n",
    "\n",
    "### STRIP_END ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
