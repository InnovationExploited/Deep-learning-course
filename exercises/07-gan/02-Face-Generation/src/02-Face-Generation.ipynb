{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â 02 - Face Generation ðŸŽ­\n",
    "\n",
    "---\n",
    "\n",
    "![](https://images.unsplash.com/photo-1528642474498-1af0c17fd8c3?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1050&q=80)\n",
    "\n",
    "Photo by [Ryoji Iwata](https://unsplash.com/photos/IBaVuZsJJTo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A GAN to generate faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For what comes next, it might be good to have a clean code under the form of a class. This part is given to you. Make sure to understand it, since you'll be asked to use it afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-29T20:27:58.518165Z",
     "start_time": "2019-05-29T20:27:58.353378Z"
    }
   },
   "outputs": [],
   "source": [
    "class GAN():\n",
    "    def __init__(self, x, y, z):\n",
    "\n",
    "        self.img_rows = x\n",
    "        self.img_cols = y\n",
    "        self.channels = z\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        \n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(\n",
    "            loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        self.generator = self.build_generator()\n",
    "        self.generator.compile(\n",
    "            loss='binary_crossentropy', \n",
    "            optimizer=optimizer)\n",
    "\n",
    "        z = Input(shape=(100,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        self.discriminator.trainable = False\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        noise_shape = (100,)\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(256, input_shape=noise_shape))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        noise = Input(shape=noise_shape)\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Flatten(input_shape=self.img_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, X_train, epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        #X_train = np.expand_dims(X_train, axis=3)\n",
    "        half_batch = int(batch_size / 2)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            noise = np.random.normal(0, 1, (half_batch, 100))\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "            valid_y = np.array([1] * batch_size)\n",
    "\n",
    "            g_loss = self.combined.train_on_batch(noise, valid_y)\n",
    "\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            if epoch % save_interval == 0:\n",
    "                self.save_imgs(epoch)\n",
    "\n",
    "    def save_imgs(self, epoch):\n",
    "        r, c = 5,5\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images_gan_face/face_%d.png\" % epoch)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GANs typically require between 10'000 and 100'000 iterations depending on the complexity of the underlying data. For this reason, running such models locally on CPUs is not such a good idea. \n",
    "\n",
    "We'll be using Google Colab's GPUs for this task. \n",
    "\n",
    "In this exercise, we'll take as inputs faces from actors of IMdB. The dataset has been already extracted and is currently under the form of a numpy array. The main steps of the exercise are to :\n",
    "- import the data\n",
    "- train a GAN on it\n",
    "- generate new faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 : Google Colab\n",
    "\n",
    "Open https://colab.research.google.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 : New notebook\n",
    "\n",
    "Create a new Notebook in Python 3 as under :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/colab.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T07:55:55.082703Z",
     "start_time": "2019-05-30T07:55:54.948636Z"
    }
   },
   "source": [
    "### Step 3 : Download the data\n",
    "\n",
    "Now, download the numpy array which contains the faces, and move the file to your Drive (Typically Drive/My Drive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T07:55:55.082703Z",
     "start_time": "2019-05-30T07:55:54.948636Z"
    }
   },
   "source": [
    "### Step 4 : Start the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your notebook, go to `Execution > Modifier le type d'exÃ©cution` and set it to GPU :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/gpu.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T07:55:55.082703Z",
     "start_time": "2019-05-30T07:55:54.948636Z"
    }
   },
   "source": [
    "### Step 5 : Allow colab to access your Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the notebook, type the following command to allow Colab to access your drive's files :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T07:57:06.407068Z",
     "start_time": "2019-05-30T07:57:05.988064Z"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Once you run the cell, a link is provided, similar to : Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Open the URL. You should now see a page asking for an access to the content of your Drive. Allow access."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, simply copy the code given, and paste it in the cell of your notebook :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T07:55:55.082703Z",
     "start_time": "2019-05-30T07:55:54.948636Z"
    }
   },
   "source": [
    "### Step 6 : Getting the right code\n",
    "\n",
    "Import the right packages and copy-paste the code of the GAN class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T07:55:55.082703Z",
     "start_time": "2019-05-30T07:55:54.948636Z"
    }
   },
   "source": [
    "### Step 7 : Import X_face.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using Colab, the file is located in your folder `Drive/My Drive` (with the space). Import the file and define X_train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T07:55:55.082703Z",
     "start_time": "2019-05-30T07:55:54.948636Z"
    }
   },
   "source": [
    "### Step 8 : Train the GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T07:55:55.082703Z",
     "start_time": "2019-05-30T07:55:54.948636Z"
    }
   },
   "source": [
    "### Step 9 : Generation !\n",
    "\n",
    "For this step, you need to generate new faces. What inputs should you give it ? Modify the class and create a \"predict\" function which takes the required input and outputs a generated face."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STRIP_START ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Solution : \n",
    "\n",
    "Colab Notebook : https://colab.research.google.com/drive/1d7wquOO6BMDWG0cKvFMXH1j29cOk4SQu#scrollTo=bLoZPDIIfI_-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FYI: `Faces to Array`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial dataset that contained the input images for the face generation challenge contains individual pictures.\n",
    "\n",
    "To speed up the exercise, we have already extracted the images using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-02T15:16:48.298323Z",
     "start_time": "2019-06-02T15:15:02.384373Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in train_files: 1\n",
      "Files in train_files: 1\n",
      "Files in train_files: 1\n",
      "Files in train_files: 1\n",
      "Files in train_files: 4299\n",
      "250 images to array\n",
      "Files in train_files: 4225\n",
      "250 images to array\n",
      "500 images to array\n",
      "750 images to array\n",
      "1000 images to array\n",
      "1250 images to array\n",
      "1500 images to array\n",
      "1750 images to array\n",
      "2000 images to array\n",
      "2250 images to array\n",
      "2500 images to array\n",
      "2750 images to array\n",
      "Files in train_files: 4240\n",
      "250 images to array\n",
      "500 images to array\n",
      "750 images to array\n",
      "1000 images to array\n",
      "1250 images to array\n",
      "1500 images to array\n",
      "1750 images to array\n",
      "2000 images to array\n",
      "2250 images to array\n",
      "2500 images to array\n",
      "2750 images to array\n",
      "Files in train_files: 4208\n",
      "250 images to array\n",
      "500 images to array\n",
      "750 images to array\n",
      "1000 images to array\n",
      "1250 images to array\n",
      "1500 images to array\n",
      "1750 images to array\n",
      "2000 images to array\n",
      "2250 images to array\n",
      "2500 images to array\n",
      "2750 images to array\n",
      "Files in train_files: 4141\n",
      "250 images to array\n",
      "500 images to array\n",
      "750 images to array\n",
      "1000 images to array\n",
      "1250 images to array\n",
      "1500 images to array\n",
      "1750 images to array\n",
      "2000 images to array\n",
      "2250 images to array\n",
      "2500 images to array\n",
      "Files in train_files: 4451\n",
      "250 images to array\n",
      "500 images to array\n",
      "750 images to array\n",
      "1000 images to array\n",
      "1250 images to array\n",
      "1500 images to array\n",
      "1750 images to array\n",
      "2000 images to array\n",
      "2250 images to array\n",
      "2500 images to array\n",
      "2750 images to array\n",
      "3000 images to array\n",
      "Files in train_files: 6181\n",
      "250 images to array\n",
      "500 images to array\n",
      "750 images to array\n",
      "1000 images to array\n",
      "1250 images to array\n",
      "1500 images to array\n",
      "1750 images to array\n",
      "2000 images to array\n",
      "2250 images to array\n",
      "2500 images to array\n",
      "2750 images to array\n",
      "3000 images to array\n",
      "3250 images to array\n",
      "3500 images to array\n",
      "3750 images to array\n",
      "4000 images to array\n",
      "Files in train_files: 5012\n",
      "250 images to array\n",
      "500 images to array\n",
      "750 images to array\n",
      "1000 images to array\n",
      "1250 images to array\n",
      "1500 images to array\n",
      "1750 images to array\n",
      "2000 images to array\n",
      "2250 images to array\n",
      "2500 images to array\n",
      "2750 images to array\n",
      "3000 images to array\n",
      "3250 images to array\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from IPython.display import Image as _Imgdis\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "dataset = []\n",
    "        \n",
    "folder = \"/Users/maelfabien/Desktop/imdb_crop/\"\n",
    "\n",
    "# Original Dimensions\n",
    "image_width = 96\n",
    "image_height = 96\n",
    "channels = 3\n",
    "nb_classes = 1\n",
    "        \n",
    "onlyfolder = [f for f in os.listdir(folder)]\n",
    "\n",
    "for fold in onlyfolder :\n",
    "    if len(dataset) > 20000 :\n",
    "        break\n",
    "    try : \n",
    "        onlyfiles = [f for f in os.listdir(folder+fold) if os.path.isfile(os.path.join(folder+fold, f))]\n",
    "\n",
    "        train_files = []\n",
    "        i=0\n",
    "\n",
    "        for _file in onlyfiles:\n",
    "            train_files.append(_file)\n",
    "\n",
    "        print(\"Files in train_files: %d\" % len(train_files))\n",
    "\n",
    "        i = 0\n",
    "        for _file in train_files:\n",
    "            img = load_img(folder + fold + \"/\" + _file)  # this is a PIL image\n",
    "            img.thumbnail((image_width, image_height))\n",
    "            # Convert to Numpy Array\n",
    "            x = img_to_array(img)  \n",
    "            try : \n",
    "                x = x.reshape((image_width, image_height, channels)).astype(int)\n",
    "                # Normalize\n",
    "                dataset.append(x)\n",
    "                i += 1\n",
    "                if i % 250 == 0:\n",
    "                    print(\"%d images to array\" % i)\n",
    "            except :\n",
    "                continue\n",
    "    except : \n",
    "        continue\n",
    "        \n",
    "np_data = np.array(dataset)\n",
    "np.save('X_face.npy', np_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STRIP_END ###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
