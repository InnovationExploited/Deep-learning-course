{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03-Amazon-Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and basic preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "import pandas as pd\n",
    "file = open('amazon_reviews.txt', 'r') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__label__2 Great CD: My lovely Pat has one of the GREAT voices of her generation. I have listened to this CD for YEARS and I still LOVE IT. When I\\'m in a good mood it makes me feel better. A bad mood just evaporates like sugar in the rain. This CD just oozes LIFE. Vocals are jusat STUUNNING and lyrics just kill. One of life\\'s hidden gems. This is a desert isle CD in my book. Why she never made it big is just beyond me. Everytime I play this, no matter black, white, young, old, male, female EVERYBODY says one thing \"Who was that singing ?\"\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [line for line in file]\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0 if x.split(' ')[0] == '__label__1' else 1 for x in data]\n",
    "sentences = [x.split(' ', 1)[1][:-1].lower() for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great cd: my lovely pat has one of the great voices of her generation. i have listened to this cd for years and i still love it. when i\\'m in a good mood it makes me feel better. a bad mood just evaporates like sugar in the rain. this cd just oozes life. vocals are jusat stuunning and lyrics just kill. one of life\\'s hidden gems. this is a desert isle cd in my book. why she never made it big is just beyond me. everytime i play this, no matter black, white, young, old, male, female everybody says one thing \"who was that singing ?\"',\n",
       " \"one of the best game music soundtracks - for a game i didn't really play: despite the fact that i have only played a small portion of the game, the music i heard (plus the connection to chrono trigger which was great as well) led me to purchase the soundtrack, and it remains one of my favorite albums. there is an incredible mix of fun, epic, and emotional songs. those sad and beautiful tracks i especially like, as there's not too many of those kinds of songs in my other video game soundtracks. i must admit that one of the songs (life-a distant promise) has brought tears to my eyes on many occasions.my one complaint about this soundtrack is that they use guitar fretting effects in many of the songs, which i find distracting. but even if those weren't included i would still consider the collection worth it.\",\n",
       " 'batteries died within a year ...: i bought this charger in jul 2003 and it worked ok for a while. the design is nice and convenient. however, after about a year, the batteries would not hold a charge. might as well just get alkaline disposables, or look elsewhere for a charger that comes with batteries that have better staying power.',\n",
       " \"works fine, but maha energy is better: check out maha energy's website. their powerex mh-c204f charger works in 100 minutes for rapid charge, with option for slower charge (better for batteries). and they have 2200 mah batteries.\",\n",
       " \"great for the non-audiophile: reviewed quite a bit of the combo players and was hesitant due to unfavorable reviews and size of machines. i am weaning off my vhs collection, but don't want to replace them with dvd's. this unit is well built, easy to setup and resolution and special effects (no progressive scan for hdtv owners) suitable for many people looking for a versatile product.cons- no universal remote.\",\n",
       " \"dvd player crapped out after one year: i also began having the incorrect disc problems that i've read about on here. the vcr still works, but hte dvd side is useless. i understand that dvd players sometimes just quit on you, but after not even one year? to me that's a sign on bad quality. i'm giving up jvc after this as well. i'm sticking to sony or giving another brand a shot.\",\n",
       " \"incorrect disc: i love the style of this, but after a couple years, the dvd is giving me problems. it doesn't even work anymore and i use my broken ps2 now. i wouldn't recommend this, i'm just going to upgrade to a recorder now. i wish it would work but i guess i'm giving up on jvc. i really did like this one... before it stopped working. the dvd player gave me problems probably after a year of having it.\",\n",
       " \"dvd menu select problems: i cannot scroll through a dvd menu that is set up vertically. the triangle keys will only select horizontally. so i cannot select anything on most dvd's besides play. no special features, no language select, nothing, just play.\",\n",
       " 'unique weird orientalia from the 1930\\'s: exotic tales of the orient from the 1930\\'s. \"dr shen fu\", a weird tales magazine reprint, is about the elixir of life that grants immortality at a price. if you\\'re tired of modern authors who all sound alike, this is the antidote for you. owen\\'s palette is loaded with splashes of chinese and japanese colours. marvelous.',\n",
       " 'not an \"ultimate guide\": firstly,i enjoyed the format and tone of the book (how the author addressed the reader). however, i did not feel that she imparted any insider secrets that the book promised to reveal. if you are just starting to research law school, and do not know all the requirements of admission, then this book may be a tremendous help. if you have done your homework and are looking for an edge when it comes to admissions, i recommend some more topic-specific books. for example, books on how to write your personal statment, books geared specifically towards lsat preparation (powerscore books were the most helpful for me), and there are some websites with great advice geared towards aiding the individuals whom you are asking to write letters of recommendation. yet, for those new to the entire affair, this book can definitely clarify the requirements for you.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "\n",
    "max_features = 10000\n",
    "\n",
    "# tokenization\n",
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "tokenized_sentences = tokenizer.texts_to_sequences(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min length: 10\n",
      "max length: 205\n",
      "mean length: 77.2038\n",
      "median length: 69.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "lengths = [len(seq) for seq in tokenized_sentences]\n",
    "print('min length:', np.min(lengths))\n",
    "print('max length:', np.max(lengths))\n",
    "print('mean length:', np.mean(lengths))\n",
    "print('median length:', np.median(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding\n",
    "maxlen = 64\n",
    "\n",
    "X = sequence.pad_sequences(tokenized_sentences, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding, Dropout\n",
    "\n",
    "def my_RNN():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=max_features, output_dim=32, input_length=maxlen))\n",
    "    model.add(SimpleRNN(units=32, return_sequences=True))\n",
    "    model.add(SimpleRNN(units=32, return_sequences=False))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "9000/9000 [==============================] - 3s 363us/sample - loss: 0.6732 - acc: 0.5650 - val_loss: 0.5400 - val_acc: 0.7240\n",
      "Epoch 2/50\n",
      "9000/9000 [==============================] - 3s 288us/sample - loss: 0.3518 - acc: 0.8444 - val_loss: 0.4667 - val_acc: 0.7770\n",
      "Epoch 3/50\n",
      "9000/9000 [==============================] - 3s 358us/sample - loss: 0.0945 - acc: 0.9716 - val_loss: 0.5557 - val_acc: 0.7800\n",
      "Epoch 4/50\n",
      "9000/9000 [==============================] - 3s 356us/sample - loss: 0.0172 - acc: 0.9961 - val_loss: 0.6828 - val_acc: 0.7680\n",
      "Epoch 5/50\n",
      "9000/9000 [==============================] - 3s 360us/sample - loss: 0.0042 - acc: 0.9998 - val_loss: 0.7185 - val_acc: 0.7940\n",
      "Epoch 6/50\n",
      "9000/9000 [==============================] - 3s 358us/sample - loss: 0.0018 - acc: 0.9998 - val_loss: 0.7811 - val_acc: 0.7810\n",
      "Epoch 7/50\n",
      "9000/9000 [==============================] - 3s 362us/sample - loss: 8.6977e-04 - acc: 1.0000 - val_loss: 0.8003 - val_acc: 0.7990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0f9d4f0b00>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "model = my_RNN()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define now our callbacks\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "             TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)]\n",
    "\n",
    "model.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), epochs=50, batch_size=64, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on train with NN: 1.0\n",
      "accuracy on test with NN: 0.799\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('accuracy on train with NN:', accuracy_score(model.predict(X_train).round(), y_train))\n",
    "print('accuracy on test with NN:', accuracy_score(model.predict(X_test).round(), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
