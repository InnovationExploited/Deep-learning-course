{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 07 - Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 08 - Generative Adversarial Networks and Adversarial Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../media/07-gan/lisa.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-29T15:18:48.110955Z",
     "start_time": "2019-05-29T15:18:48.107430Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. What is a GAN ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Big Picture** : Generative Adversarial Networks (GANs) are deep learning architectures made of 2 Neural Nets, fighting one against the other. \n",
    "\n",
    "- A first network is train to take a random input and try to make it look like our target data.\n",
    "\n",
    "- A second network is trained to recognize the fake inputs from the true inputs. \n",
    "\n",
    "We use the fact that these 2 networks fight against one another to learn the distribution of the input data and generate new data samples. Thus, GANs are said to be a **generative model**.\n",
    "\n",
    "Therefore, GANs are able to generate :\n",
    "- faces\n",
    "- images\n",
    "- videos\n",
    "- voices\n",
    "- data\n",
    "- and even art..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-29T18:51:32.197567Z",
     "start_time": "2019-05-29T18:51:32.188322Z"
    }
   },
   "source": [
    "Concretely, you can apply GANs to :\n",
    "- Font generation\n",
    "- Anime character generation\n",
    "- Interactive Image generation\n",
    "- Text2Image (text to image)\n",
    "- 3D Object generation\n",
    "- Image Editing\n",
    "- Face Aging\n",
    "- Human Pose Estimation\n",
    "- Domain-transfer (e.g. style-transfer, pix2pix, sketch2image)\n",
    "- Image Inpainting (hole filling)\n",
    "- Super-resolution\n",
    "- High-resolution image generation (large-scale image)\n",
    "- Adversarial Examples (Defense vs Attack)\n",
    "- Visual Saliency Prediction (attention prediction)\n",
    "- Object Detection/Recognition\n",
    "- Robotics\n",
    "- Video (generation/prediction)\n",
    "- Synthetic Data Generation\n",
    "- Upscaling old 2D video games to 4K resolution\n",
    "- ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-29T15:02:56.303507Z",
     "start_time": "2019-05-29T15:02:56.298066Z"
    }
   },
   "source": [
    "## 2. Illustration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** Some art generated by GANs, from the Art and Artificial Intelligence Laboratory, Rutgers University, and sold for 432'000 $\n",
    "\n",
    "<img src=\"images/art.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** Faces generated by GANs. None of these people actually exist. These faces were generated on https://www.thispersondoesnotexist.com/\n",
    "\n",
    "<img src=\"images/faces.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** Anime characters generated by NVIDIA using the algorithm StyleGAN\n",
    "\n",
    "<img src=\"images/anime.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-29T15:17:26.707108Z",
     "start_time": "2019-05-29T15:17:26.703855Z"
    }
   },
   "source": [
    "**4)** GAN-Generated Music by Aiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:00:05.646794Z",
     "start_time": "2019-06-03T09:00:05.638119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"100%\" height=\"166\" scrolling=\"no\" frameborder=\"no\" allow=\"autoplay\" src=\"https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/522141435&color=%23ff5500&auto_play=false&hide_related=false&show_comments=true&show_user=true&show_reposts=false&show_teaser=true\"></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe width=\"100%\" height=\"166\" scrolling=\"no\" frameborder=\"no\" allow=\"autoplay\" src=\"https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/522141435&color=%23ff5500&auto_play=false&hide_related=false&show_comments=true&show_user=true&show_reposts=false&show_teaser=true\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5)** GAN for data generation\n",
    "\n",
    "https://poloclub.github.io/ganlab/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1959 : The general idea of learning via competition between players dates back to at least 1959. **Arthur Samuel**, demonstrated that algorithms could learn to play checkers via adversarial self-play.\n",
    "\n",
    "- 1992 : Works by JÃ¼rgen Schmidhuber on Predictibility Minimization, a form of Adversarial Networks https://youtu.be/HGYYEUSm-0Q?t=3779\n",
    "\n",
    "- 2014 : Ian Goodfellow is recognized by several sources as having **invented GANs** in 2014. His paper included the first working implementation of a generative model based on adversarial networks, as well as game theoretic analysis establishing that the method is sound.\n",
    "https://arxiv.org/abs/1406.2661\n",
    "\n",
    "- 2017 : A GAN was used for **image enhancement** focusing on realistic textures rather than pixel-accuracy, producing a higher image quality at high magnification.\n",
    "\n",
    "- 2017 : The first **faces** were generated. These were exhibited in February 2018 at the Grand Palais.\n",
    "\n",
    "- 2017 : GAN technology began to make its presence felt in the **fine arts** arena with the appearance of a newly developed implementation which was said to have crossed the threshold of being able to generate unique and appealing abstract paintings, and thus dubbed a \"CAN\", for \"creative adversarial network\".\n",
    "\n",
    "- 2018 : A GAN system was used to create the 2018 **painting** Edmond de Belamy, which sold for 432'500 USD\n",
    "\n",
    "- 2019 : Researchers at Samsung demonstrated a GAN-based system that produces **videos of a person** speaking given only a single photo of that person."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/facebook.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. How do GANs work ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> GANs are used to Generate data that follow a target distribution, from a random input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/GANprinciple.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> GANs are based on the notion of Adversarial Training. Adversarial training is a technique employed in the field of machine learning which attempts to fool models through malicious input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generative Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 main ways to generate data :\n",
    "- by directly comparing the generated data and the input data :  Generative Matching Networks\n",
    "- by indirectly comparing the generated data and the input data : Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Generative Matching Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generative Matching Networks is a category of algorithms made of :\n",
    "- Generative Moments Matching Networks\n",
    "- Generative Features Matching Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We **compare the true and the generated probability distributions** and backpropagating the difference (the error) through the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/GMN.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, we usually compute the error by Maximum Mean Discrepancy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In GANs, we don't compute the error directly. We train a discriminator to recognize the true and the generated images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GANs are made of 2 Neural Nets :\n",
    "- A Generator : `G(z)`\n",
    "- A Discriminator : `D(x)`\n",
    "\n",
    "We have in a sense, 2 inputs :\n",
    "- Real data\n",
    "- Generated data (by the Generator)\n",
    "\n",
    "We try to :\n",
    "- teach the discriminator to recognize real data and generated data,\n",
    "- teach the generator to make generated data look like real data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/GANschema.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In adversarial training, both networks try to beat each other and, doing so, they are both becoming better and better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Architecture Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-29T15:32:53.487420Z",
     "start_time": "2019-05-29T15:32:53.480478Z"
    }
   },
   "source": [
    "<img src='images/GANs.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Discriminator : D(x)\n",
    "\n",
    "> If you input a `x` data point through `D(x)`, it will output a value between 0 and 1, which is the probability that `x` is from the original dataset.\n",
    "\n",
    "If we successfully manage to generate data that look like the input data, our discriminator should have issues telling which image is real or fake. In this sense, we expect the probability that it outputs to tend to 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    \n",
    "    img = Input(shape=img_shape)\n",
    "    \n",
    "    # Create the sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Flatten the images taken as inputs\n",
    "    model.add(Flatten(input_shape=img_shape))\n",
    "    \n",
    "    # First layer\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # Many layers ...\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Get result\n",
    "    validity = model(img)\n",
    "    \n",
    "    return Model(img, validity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/disc.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Generator : G(x)\n",
    "\n",
    "> The Generator `G(z)` takes as input a noise vector, called `z`. Then, the generator learns to output a generated data from this noise input. The output of G(z) is a matrix whose dimensions are equal to the true inputs. \n",
    "\n",
    "Ideally, we want `G(z)` to output matrices which are indistinguishable from the original data (x) distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "\n",
    "    # Input Data\n",
    "    noise_shape = (100,)\n",
    "    noise = Input(shape=noise_shape)\n",
    "    \n",
    "    # Create the sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Build the first layer\n",
    "    model.add(Dense(256, input_shape=noise_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    \n",
    "    # Many layers...\n",
    "    \n",
    "    # Flatten and reshape\n",
    "    model.add(Dense(np.prod(img_shape), activation='tanh'))\n",
    "    model.add(Reshape(img_shape))\n",
    "\n",
    "    # Get result\n",
    "    img = model(noise)\n",
    "    \n",
    "    return Model(noise, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/gen.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-29T15:55:03.683774Z",
     "start_time": "2019-05-29T15:55:03.675659Z"
    }
   },
   "source": [
    "#### Practical considerations :\n",
    "\n",
    "Here's some practical considerations for building your first GAN :\n",
    "- Usually the discriminator âwinsâ\n",
    "- Usually D is bigger and deeper than G\n",
    "- Sometimes train D more often than G.\n",
    "- Do not try to limit D to avoid making it âtoo smartâ \n",
    "- Use gaussian distribution for input Noise\n",
    "- Use non-saturating functions (ReLu, MaxPool)\n",
    "- Use Soft and Noisy Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A bit of Maths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective function in GANs is the following : \n",
    "\n",
    "<img src='images/eq2.png'>\n",
    "\n",
    "What does it mean ?\n",
    "\n",
    "- We train **D** to **maximize** the probability of assigning the correct label to both training examples and samples from G. \n",
    "- We simultaneously train **G** to **minimize** `(1 â D(G(z)))`\n",
    "\n",
    "In other words, D and G play a two-player **minimax** game with value function `V(G, D)`\n",
    "\n",
    "<img src='images/eq3.png'>\n",
    "\n",
    "- Optimizing D is computationally prohibitive, and on finite datasets would result in overfitting. \n",
    "- Instead, we alternate between `k` steps of optimizing D and `one` step of optimizing G. \n",
    "\n",
    "This results in D being maintained near its optimal solution, while G changes slowly.\n",
    "\n",
    "<img src='images/process.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. How to train a GAN ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-02T15:33:16.270683Z",
     "start_time": "2019-06-02T15:33:16.190316Z"
    }
   },
   "source": [
    "A full list of useful recommendations can be found here : https://github.com/soumith/ganhacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New papers are constantly coming out, but here's a general list of recommendations to train a GAN :\n",
    "- Normalize the inputs\n",
    "- In GAN papers, the loss function to optimize G is : min (log 1-D), but in practice we practically use : max log D\n",
    "- Sample input data from a Gaussian distribution rather than a uniform one\n",
    "- Construct different mini-batches for real and fake, i.e. each mini-batch needs to contain only all real images or all generated images\n",
    "- Avoid Sparse gradients such as Relu and Maxpool.LeakyRelu is good for both the generator and the discriminator.\n",
    "    - For Downsampling, use: Average Pooling, Conv2d + stride\n",
    "    - For Upsampling, use: PixelShuffle, ConvTranspose2d + stride\n",
    "- Soft and Noisy labels : If you have two target labels: Real=1 and Fake=0, then for each incoming sample, if it is real, then replace the label with a random number between 0.7 and 1.2, and if it is a fake sample, replace it with 0.0 and 0.3 (for example).\n",
    "- Use Stochastic Gradient Descent for the discriminator and ADAM for the generator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Types and variations of GANs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might guess, since GANs are really recent, there's an expending and active litterature on this topic. What we covered so far is only the basis of GANs. In this section, we'll cover some extensions and twists of GANs, what they bring and what they can be used for. There are many, many, many types of GANs, including :   \n",
    "- Auxiliary Classifier Generative Adversarial Network\n",
    "- Adversarial Autoencoder\n",
    "- Bidirectional GAN\n",
    "- Boundary-Seeking GAN\n",
    "- Conditional GAN\n",
    "- Context-Conditional GAN\n",
    "- CycleGAN\n",
    "- Deep Convolutional GAN\n",
    "- Semi-Supervised GAN\n",
    "- ...\n",
    "\n",
    "\n",
    "We obviously won't cover all of them, but here are the major improvments to classical GANs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. StarGAN and InfoGAN\n",
    "\n",
    "https://arxiv.org/pdf/1711.09020.pdf\n",
    "\n",
    "> StarGANs give non-random inputs to a GAN (i.e an image), and learn multiple mapping at a time to avoid overfitting, \n",
    "\n",
    "We call the fact of feeding an information input instead of noise an **InfoGAN**.\n",
    "\n",
    "StarGANs are implemented in PyTorch. Pre-trained models exist in the context of face features generation (Blond, Brunette, but also emotions like happiness or sadness)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/star.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Deep Convolutional GANs\n",
    "\n",
    "https://arxiv.org/pdf/1511.06434.pdf\n",
    "\n",
    "> DCGANs are an improvement of GANs and use CNNs instead of systematically using Dense networks.\n",
    "\n",
    "They are more stable and generate higher quality images, since they use CNNs. In DCGAN, **batch normalization** is done in **both networks**, i.e the generator network and the discriminator network. They can be used for style transfer. For example, you can use a dataset of handbags to generate shoes in the same style as the handbags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/bags.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conditional GANs (pix2pix)\n",
    "\n",
    "https://arxiv.org/pdf/1411.1784.pdf\n",
    "\n",
    "> Generative adversarial nets can be extended to a conditional model if both the generator and discriminator are conditioned on some extra information y, for example a label.\n",
    "\n",
    "These GANs use extra label information and result in better quality images and are able to control how generated images will look."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T10:05:34.084457Z",
     "start_time": "2019-06-03T10:05:34.075458Z"
    }
   },
   "source": [
    "<img src='images/cgans.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. StackGAN\n",
    "\n",
    "https://arxiv.org/pdf/1612.03242.pdf\n",
    "    \n",
    "StackGANs synthetize high-quality images from text descriptions in computer vision. They propose Stacked Generative Adversarial Networks (StackGAN) to generate 256x256 photo-realistic images conditioned on text descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/sgans.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Least Square GAN (LSGAN)\n",
    "\n",
    "https://arxiv.org/pdf/1611.04076.pdf\n",
    "\n",
    "Regular GANs may lead to the vanishing gradients problem, which therefore slows the learning process.\n",
    "\n",
    "LSGAN attempts to overcome this problem by adopting the least squares loss function instead of the sigmoid cross entropy loss for the discriminator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Auxiliary Classifier GAN (ACGAN)\n",
    "\n",
    "https://arxiv.org/pdf/1610.09585.pdf\n",
    "\n",
    "In ACGANâs, every generated sample has a corresponding class label C in addition to the noise Z.\n",
    "\n",
    "G uses both to generate images : $X=G(C,Z)$. The discriminator gives both a probability distribution over sources and a probability distribution over the class labels.\n",
    "\n",
    "Authors demonstrate that that adding more structure to the GAN latent space along with a specialized cost function results in higher quality samples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
