{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 07 - Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 03 - CNN Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://images.unsplash.com/photo-1542378993-3aa1366b0090?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1050&q=80)\n",
    "Picture by [Sergey Pesterev](https://unsplash.com/photos/PChvdQjvTO4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We will learn today about one of the most famous kind of Deep Learning method: the Convolutional Neural Networks (sometimes called ConvNets or CNN). But before, we need to talk a bit about image processing, in order to introduce necessary tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Computer Vision introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images are just numbers! So all we learnt about Machine Learning and Deep Learning has to work with images, both classification and regression!\n",
    "![](images/computer_vision_task.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But unlike other kind of data, images have **spatial structure**! Indeed, the same object can be seen from various viewpoints, deformed, scaled, occluded, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/Computer_Vision_limits.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's why in order to take full advantage of this spatial structure, we need in **add spatial information in our models**. This is where Convolutional Neural Networks (CNN) take place! So first, let's talk a bit about image processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# II. Image Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.1. Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paddind an image is adding borders to it, thus increasing the size of the image. Most of the time, images are padded with zeros.\n",
    "\n",
    "Below is an example of a 4x4 image before padding, and after padding:\n",
    "\n",
    "![](images/padding_image.png)\n",
    "\n",
    "Padding can also add more than one line of zeros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.2. Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A kernel in image processing is nothing more than a small image (or a small matrix), that we will use to make a convolution.\n",
    "\n",
    "Thus, a kernel is necessary smaller than the image. Usually, kernels have odd dimensions, and are quite small. Typical sizes of kernels are:\n",
    "* 3x3\n",
    "* 5x5\n",
    "* 7x7\n",
    "* 9x9\n",
    "\n",
    "Depending on the values of the kernel, the convolution will provide different results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.3 Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A convolution is a mathematical operation that you already encountered. For example, below is the convolution result of an image with a 3x3 kernel of ones:\n",
    "\n",
    "![](images/convolution_animated.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But as you know, the kernel can have different values. Below is an example of a convolution of an image I with a non uniform kernel K:\n",
    "\n",
    "![](images/convolution_kernel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A wisely chosen kernel can be really useful to detect patterns in images. Here is a list of commonly used kernels and what they do on a given image (from [wikipedia](https://en.wikipedia.org/wiki/Kernel_(image_processing)):\n",
    "\n",
    "| Kernel | Usage | Example |\n",
    "|:--:|:--:|:--:|\n",
    "| \\begin{bmatrix}\n",
    "0 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 0\n",
    "\\end{bmatrix}| Identity | ![](images/Vd-Orig.png)  |\n",
    "|\\begin{bmatrix}\n",
    "\\ \\ 1 & 0 & -1 \\\\\n",
    "\\ \\ 0 & 0 & \\ \\ 0 \\\\\n",
    "-1 & 0 & \\ \\ 1\n",
    "\\end{bmatrix} | Edge detection | ![](images/Vd-Edge1.png)  |\n",
    "| \\begin{bmatrix}\n",
    "0 &  \\ \\ 1 & 0 \\\\\n",
    "1 & -4 & 1 \\\\\n",
    "0 &  \\ \\ 1 & 0\n",
    "\\end{bmatrix}| Identity | ![](images/Vd-Edge2.png)  |\n",
    "| \\begin{bmatrix}\n",
    "-1 &  -1 & -1 \\\\\n",
    "-1 & \\ \\ 8 & -1 \\\\\n",
    "-1 &  -1 & -1\n",
    "\\end{bmatrix}| Edge detection | ![](images/Vd-Edge3.png)  |\n",
    "| \\begin{bmatrix}\n",
    "\\ \\ 0 & -1 & \\ \\ 0 \\\\\n",
    "-1 & \\ \\ 5 & -1 \\\\\n",
    "\\ \\ 0 & -1 & \\ \\ 0\n",
    "\\end{bmatrix}| Sharpening | ![](images/Vd-Sharp.png)  |\n",
    "| \\begin{bmatrix}\n",
    "1 & 2 & 1 \\\\\n",
    "2 & 4 & 2 \\\\\n",
    "1 & 2 & 1\n",
    "\\end{bmatrix}| Gaussian blur | ![](images/Vd-Blur1.png)  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to summarize, a convolution is a mathematical operation on a image with a given kernel, resulting in a new processed image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.4. Strides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to now, we know how to compute a convolution, with a given kernel, and to pad an image. The last tool needed is what is called stride.\n",
    "\n",
    "The stride value is the step between two convolutions with a kernel. For the moment, all we did was with a stride of one, as in the example below:\n",
    "\n",
    "![](images/Stride1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as we see in this example, an image of dimension 7x7, convoluted with a kernel of 3x3 results in an image of 5x5.\n",
    "\n",
    "What if we use a stride of 2, meaning our kernel with use a step of 2 on our image:\n",
    "\n",
    "![](images/Stride2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a stride of 2, an input image of dimension 7x7 convoluted with a kernel of 3x3 results in an image of 3x3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why would we use convolutions in neural networks? Isn't a MLP complicated enough?\n",
    "\n",
    "Well, indeed MLP are complicated enough, but they do not take into account *spatial* correlations. Indeed in an image, there are spatial correlations everywhere:\n",
    "* In a face the eye is always close to the nose, and the nose is always in the middle of the face.\n",
    "* A bike always has two wheels.\n",
    "* All numbers and letters have a particular shape.\n",
    "\n",
    "For all of those examples, a classical MLP will not see the spatial correlations, and might have to learn them by itself. But if you add convolutions, this is far more easier to understand the structure of the data for the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Historically, convolutional neural networks were not always famous. Yann Le Cun, commonly admitted as one of the creators of this technique, is now a rock star in AI, but had rough years in academic research in the past.\n",
    "\n",
    "CNNs exploded with [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) in 2012, a CNN that made a breakthrough in the Computer Vision field. Since then, CNNs are quite popular and widely used in the Computer Vision are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/CNN_features_levels.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.2. Convolutional Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a CNN, we need first to make a Convolutional Layer. A convolutional layer is simply a convolution on our input data, with several options to choose: the size of the kernel, the padding and the stride. \n",
    "\n",
    "Here is the signature in TensorFlow:\n",
    "\n",
    "`tensorflow.keras.layers.Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)`\n",
    "\n",
    "With especially the following parameters to use:\n",
    "* `filters`: the number of kernels to use\n",
    "* `kernel_size`: the size of the kernels (e.g. `(3,3)` for a 3x3 kernel)\n",
    "* `padding`: `valid` for no padding, `same` to keep the same dimensions for the image\n",
    "* `kernel_regularizer`: to add regularization\n",
    "\n",
    "We will see how to use it in an example in the last section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.3. Pooling Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pooling layer is a layer that will reduce the size of the images by taking the average or max value of a given number of pixels.\n",
    "\n",
    "Below is an example of pooling layer, with a kernel of 2x2 and a stride of 2 applied on an image of 4x4:\n",
    "\n",
    "![](images/max_pooling.jpeg)\n",
    "\n",
    "A pooling layer is usually used right after a convolutional layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pooling layers are defined in Keras as well, with the following signature:\n",
    "\n",
    "`tensorflow.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)`\n",
    "\n",
    "Where:\n",
    "* `pool_size` is the dimensions of the kernel\n",
    "* `strides` is the stride value, if `None` the value will be the same as `pool_size`\n",
    "* `padding` can be `valid` for no padding or `same` for keeping image dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. LeNet-5 on MNIST digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV.1. Architecture diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first see the architecture of the LeNet-5: this is the algorithm that was proposed by [LeCun et al.](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf) for digit classification using convolutional networks.\n",
    "\n",
    "![](images/Lenet5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now decompose and explain the layers step by step:\n",
    "* Input (32x32): this is the input image of a digit\n",
    "* C1 (6@28x28): this is a convolutional layer of 3x3 with 6 filters\n",
    "* S2 (6@14x14): this is a max pooling layer of 2x2\n",
    "* C3 (16@10x10): this is a convolution layer of 3x3 with 10 filters\n",
    "* S4 (16@5x5): this is a max pooling layer of 2x2\n",
    "* C5 (120): this is a fully connected layer (MLP) of 120 units\n",
    "* F6 (84): this is a fully connected layer (MLP) pf 84 units\n",
    "* Output (10): this is a softmax layer of 10 units (1 units per digit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV.2. Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of the LeNet-5 algorithm would be the following in Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import MaxPooling2D, Conv2D, Flatten, Dense\n",
    "\n",
    "\n",
    "def lenet5():\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    # Layer C1\n",
    "    model.add(Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "    # Layer S2\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Layer C3\n",
    "    model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "    # Layer S4\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Before going into layer C5, we flatten our units\n",
    "    model.add(Flatten())\n",
    "    # Layer C5\n",
    "    model.add(Dense(units=120, activation='relu'))\n",
    "    # Layer F6\n",
    "    model.add(Dense(units=84, activation='relu'))\n",
    "    # Output layer\n",
    "    model.add(Dense(units=10, activation = 'softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV.3. Application to MNIST Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now apply this model to the MNIST digits classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "# Import the dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale the data\n",
    "X_train = X_train/255.\n",
    "X_test = X_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "# Transform the targets to categorical vectors\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 14s 232us/sample - loss: 0.2299 - acc: 0.9310 - val_loss: 0.0712 - val_acc: 0.9768\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 17s 278us/sample - loss: 0.0710 - acc: 0.9780 - val_loss: 0.0574 - val_acc: 0.9822\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 16s 269us/sample - loss: 0.0517 - acc: 0.9840 - val_loss: 0.0595 - val_acc: 0.9794\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 18s 304us/sample - loss: 0.0419 - acc: 0.9869 - val_loss: 0.0443 - val_acc: 0.9844\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 20s 328us/sample - loss: 0.0341 - acc: 0.9884 - val_loss: 0.0413 - val_acc: 0.9856\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 17s 287us/sample - loss: 0.0283 - acc: 0.9905 - val_loss: 0.0367 - val_acc: 0.9871\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 18s 299us/sample - loss: 0.0236 - acc: 0.9924 - val_loss: 0.0383 - val_acc: 0.9876\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 18s 297us/sample - loss: 0.0198 - acc: 0.9934 - val_loss: 0.0503 - val_acc: 0.9846\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 18s 301us/sample - loss: 0.0183 - acc: 0.9936 - val_loss: 0.0367 - val_acc: 0.9883\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 18s 302us/sample - loss: 0.0153 - acc: 0.9949 - val_loss: 0.0375 - val_acc: 0.9872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff9e0590e48>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "# Instantiate the model\n",
    "model = lenet5()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define the callbacks\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "            TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)]\n",
    "\n",
    "\n",
    "# Finally fit the model\n",
    "model.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), epochs=10, batch_size=64, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 9s 146us/sample - loss: 0.0117 - acc: 0.9963\n",
      "accuracy on train with NN: 0.9963167\n",
      "10000/10000 [==============================] - 2s 171us/sample - loss: 0.0375 - acc: 0.9872\n",
      "accuracy on test with NN: 0.9872\n"
     ]
    }
   ],
   "source": [
    "# Compute the accuracy\n",
    "print('accuracy on train with NN:', model.evaluate(X_train, y_train)[1])\n",
    "print('accuracy on test with NN:', model.evaluate(X_test, y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our algorithm has about 99% accuracy. Amazing, right?!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
